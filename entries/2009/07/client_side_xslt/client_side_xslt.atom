<?xml version="1.0" encoding="UTF-8"?>
<entry xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <author>
    <name>Sigfrid Lundberg</name>
  </author>
  <title>XML on the web, Client Side XSLT and Google</title>
  <link href="/entries/2009/07/client_side_xslt/"/>
  <summary>The market has forced the major browser manufacturers to converge
  on standards. But why are the search engines lagging behind? Browsers are
  capable of AJAX and advanced XML processing, but the search engines are
  still basically just removing tags and presenting raw text extracts.</summary>
  <content type="xhtml">
    <div xmlns="http://www.w3.org/1999/xhtml">

      <p>The market has forced the major browser manufacturers to converge on
      standards. Microsoft cannot afford to produce a browser that won't work
      on google apps, and the Linux based netbooks and netboxes make a
      difference. If <a href="http://en.wikipedia.org/wiki/Software_as_a_service">software is a
      service</a>, what is the client? Obviously the web client, the
      browser. But why are the search engines lagging behind?  Browsers are
      capable of AJAX and advanced XML processing, but the search engines are
      still basically just removing tags and presenting raw text extracts.</p>

      <p>I have quite a few documents on this site that are written in raw
      XML, such as <a href="/2008/dighum/digital_humanities.xml">Digital
      Humanities Infrastructures</a> position paper from last year. Since it
      is about digital humanities and text encoding, I wrote it in <a href="http://www.tei-c.org/">TEI</a> XML. The paper is presented using
      client side XSLT. Just view source on that note, and you'll see my
      markup. The document is a blatant show-off; it is written in nerdcore
      vanity. At the top you'll see</p>

      <pre>
	&lt;?xml version="1.0" encoding="UTF-8" ?&gt;
	&lt;?xml-stylesheet href="render.xsl" type="text/xsl" ?&gt;
      </pre>

      <p>The <kbd>xml-stylesheet</kbd> processing instruction is read by your
      browsser, which then retrieves the stylesheet <a href="/2008/dighum/render.xsl">render.xsl</a>. Without any further ado
      it is then transformed into html, rendered using the CSS indicated by my
      XSLT script for you to read. You can even inscpect the resulting html
      using <a href="http://getfirebug.com/">firebug</a>, if you've got a
      modern installation.</p>

      <h2>What does Google do when indexing XML?</h2>

      <p>There is almost certainly a range of XML formats that is actually
      interpreted by Google. Which formats, well we don't know but in practice
      can hardly expect anything more exotic than common syndication formats
      (such as RSS and ATOM ), <a href="http://google.com/support/webmasters/bin/answer.py?hl=en&amp;answer=99170">microformats
      and RDFa</a>. I have noticed that Google has been doing OAI harvesting
      for many years, most likely for the benefit of <a href="http://scholar.google.com/">Scholar</a>.</p>

      <p>One could envisage a number of viable indexing strategies for a
      general search engine for a document like my Digital Infrastructure
      Nerdcore Vanity paper. One would be to execute a global regex search and
      replace "&lt;[^&gt;]+&gt;" with "" (which basically means: remove
      anything between angle brackets, or remove all tags).</p>

      <p>This would yield a "detagged incipit", which in this case is "Digital
      Humanities Infrastructures 2008-06-12 Digital Humanities Infrastructures
      Sigfrid Lundberg"</p> 

      <p>Another strategy would be to use the style sheet provided by the nerd
      publishing this paper. That would yield the "transformed incipit", which
      for this document is (using the HTML body only) "Digital Humanities
      Infrastructures Sigfrid Lundberg". In using the transform, Google would
      then be able to use its usual HTML indexing techniques. For instance it
      would understand the title, and be able parse all hypertext links.</p>

      <p>I made the search <a href="http://www.google.com/search?hl=en&amp;q=digital+humanities+infrastructure+%2Blundberg&amp;btnG=Search">digital
      humanities infrastructure +lundberg</a> and the results looks like
      "<strong>Digital Humanities Infrastructures 2008-06-12 Digital
      Humanities ...</strong> - Jun 5 ... Digital Humanities Infrastructures
      Sigfrid Lundberg slu@kb.dk Digital .... Also McCarty's humanities
      computing research infrastructure (or rather ..."</p>

      <p>The machine is actually using a detagged incipit as the title, which
      is what I think it uses for PDF. This is very far from the ideas in
      <a href="http://www.w3.org/TR/grddl/">Gleaning Resource Descriptions
      from Dialects of Languages (GRDDL)</a> where providers of documents
      actually provide XSLT for the benefit of robots that could use that to
      extract descriptions in RDF.</p>

    </div>
  </content>
  <dc:date>2009</dc:date>
  <category label="structuralwebdesign" term="Structural web design"/>
  <updated>2009-07-11T17:07:18+01:00</updated>
  <id>http://www.sigfrid-lundberg.se/entries/2009/07/client_side_xslt/</id>
</entry>
