<?xml version="1.0" encoding="ISO-8859-1" ?>

<html>
<head>
<title>Curriculum Vitae</title>
</head>
<body>

<h1 class="title">Curriculum Vitae for S. Lundberg</h1>

<h2>0. The beginning</h2>

<p class="noindent">Born 1956. Completed upper secondary 1975. B.Sc. in Ecology and
life sciences, inorganic and physical chemistry 1979.</p>

<h2>1. Scientific Career</h2>

<p class="noindent">Ph. D. 1985: Thesis <i>Five theoretical excursions into
evolutionary ecology,</i> Lund 1985.  Docent (approximately associate
professor, although untenured) 1995.</p>

<h2>1.1. Positions and research/development projects after graduation</h2>

<p class="noindent" >Postdoc (financed by Swedish Natural Sciences
Research Council, NFR) at Imperial College, London, in Parasite
Epidemiology Research Group visiting Prof. Roy Anderson, FRS.</p>


<p>Assistant professor (forskarassistent, NFR) 1 July 1987 to 1 July
1993.  Since 1 October 1993-1995 working on the following projects</p>

<ol>

<li>Evolutionary aspects on the epidemiology of childhood
diseases.</li>

<li> Pollinator foragering behaviour and the dynamics and evolution of
pollinator--plant-systems.</li>

</ol>

<p >Since October 1995 scientist at the Lund university library,
working on various development projects concerning Internet search and
information retrieval, design of our harvesting robot and archiving of
WWW documents.</p>

<h2>1.2. Teaching and supervision</h2>

<p class="noindent">The first few years as a post-graduate student I had higher
teaching load than most students average (initially my position
required 50% teaching).  Later I have lectured mathematics for
post-graduate students in ecology. I have been the supervisor of two
post-graduate students who have successfully completed their
theses. In addition I have regularly lectured on ecological modelling
techniques and evolutionary genetics to students of theoretical
ecology.</p>

<h2>2. Computing and inter-networking</h2>

<p class="noindent">As a natural scientist I have no formal merits in neither computer
science, nor in software engineering. My knowledge stems from the
following sources:</p>

<ol>

<li>Many years experience of scientific computing within areas where
shrink wrapped software is virtually absent, and in particular using
numerical analysis.</li>
<li>Many years experience of system administration (Unix ) within the
Dept of Theoretical Ecology and NetLab.</li>
<li>Several years experience of inter-networking, initially at the Dept
of Theoretical Ecology, and later at Lund University Library's
development depart NetLab.</li>

</ol>

<p>In the following I give <i>examples</i> of achievements within the
area of software engineering and inter-networking.  (In doing that, I
will ignore the area, scientific computing, in which I have gained my
proficiency in computer programming.)</p>

<h2>2.1. Operating systems</h2>

<p class="noindent">I have used computers intensely throughout my
entire career within research and development.  During the first five
years (1979-1984) I wrote my applications on the university mainframe
running the operating system OS1100.  During that period I spent a
significant proportion of my time punching cards.  Later on I acquired
a personal computer and used MS DOS (1985-1987), after that VMS on
Digital VAX computers.</p>

<p>Since 1989 I have been using Unix exclusively for all applications
and as a Unix user I have been my system administrator. I have
experience of System V (AIX, Linux and Solaris) Berkeley UNIX (Ultrix
and SunOS). I have been using Linux since release 0.13.</p>

<h2>2.2. Programming</h2>

<p class="noindent">I'm programming in Perl, C, and Fortran. I can, if
needed do work in LISP, PROLOG, TCL, SQL (if that count as a
programming language) and and MatLab. At gunpoint, I'll do Javascript
as well.</p>

<h2>2.3. Scientific typesetting</h2>

<p class="noindent">I have a sincere interest in the formatting of
scientific text, and is using GNU troff for the purpose
(&quot;groff&quot;--the printed version of this document is formatted
using that system).  I am also able to do program macros and customize
macro packages in groff. This means that I can process preprocess
documents, create indexing scripts. This means that I can handle
complete scientific books or journal issues including automatic
generation of tables of contents, index of authors, subjects and
whatever, backward and forward cross references and the like. I manage
to handle TeX and Latex if need be, but I have much less experience in
writing macros, and in general manipulate such documents.</p>

<p>I am also interested in the photo typesetting of graphs and charts
and I am the author of the gnuplot pic driver, which makes it possible
to typeset graphs using groff and annotate those with mathematical
symbols. I have contributed the widely used Linux vgalib driver for
the popular ghostscript postscript interpreter.</p>

<p>This document was created as a hypertext document in XML (actually
in XHTML) and translated into groff using XSLT and printed on a
postscript printer. That is, a typical procedure expected to operate
in an electronic publishing system with print on demand facilities.</p>

<h2>2.4. Markup languages</h2>

<p class="noindent">The last five years or so, I have interested in
manipulating structured text. Originally, I was forced into this by
the fact that I was involved in extracting data from HTML in the
harvesting systems we have developed at NetLab (see below). More
recently I have been working with XML (and to some extent SGML) as a
transfer syntax for metadata as well as in the context of scientific
publishing.</p>

<p>In both contexts I have experience of the transformation of XML
using XSLT. As regards metadata, I have used it for translation between
internal formats and different exchange formats as well as for
translating XML for presentation and human consumption. For documents,
I have used it for transforming XML/XHTML (i.e., HTML redefined using
XML rather than HTML).</p>

<h2>2.5. TCP/IP and inter-networking</h2>

<p class="noindent">I have experience of using and maintaining servers
for most popular TCP/IP protocols appearing in an Unix environment,
including SMTP, WAIS and Z39.50 databases, HTTP, ftp and gopher.  In
addition I have experience of maintaining mailing-lists, line printing
using Berkeley LPD, NFS etc.</p>

<p>Z39.50 is a protocol for information retrieval, and the protocol I
am most familiar with beside the usual suite (mostly the ones
mentioned above that are lumped together and labelled Worldwide Web --
WWW is in principle those protocols that permit access through
URLs). The public interfaces for most databases I have been involved
in, the access protocol have been Z39.50. This is for compatibility
between web search engines and library OPACs.</p>

<p>I have extensive knowledge of CGI programming. Just one advanced is
an application I wrote 1994-1995 is my now defunct &quot;Simulation
server&quot; (I have still a version running offline at home). It was
written in two programming languages Perl and Octave and used gnuplot
scripting for plotting and various graphics utilities for delivering
images on the web. Octave was used for integrating systems of ordinary
differential equations on the server, and results were presented the
graphically. The user communicated with the server using HTML forms
and a web client. Later I have created a diversity of web based
interfaces, for searching and maintaining databases and other similar
tasks.</p>

<p>One of my specialties is harvesting of web resources for building
resource discovery databases. At NetLab I have been engaged in coding
the Combine harvesting robot. It is well suited for up to medium size
harvesting projects (leading to databases up to 5.000.000 records).
The Combine is written in perl and C++, and is a package of programs
using custom TCP/IP protocols for inter-process communication. Through
its architecture it may be run on a cluster of UNIX systems for
enhanced performance. In practice we usually have a monolithic
installation on a single system.</p>

<h2>3. Activities, Projects and services</h2>

<h2>3.1 Projects and services</h2>

<p class="noindent">Early projects, commenced before becoming NetLab
staff:</p>

<dl>
<dt>Theretical Ecology Simulation Server (1994-1995)</dt>
<dd>See above</dd>
<dt>Fråga en ekolog, Ask an ecologist (1995-1996)</dt>
<dd>A service for the general public, where a panel of ecologists
answer question on ecological and environmental issues. Comprised
scripts that received questions via HTML forms, posted these on a
mailing list. Panel members answered questions again using forms. The
answers were automatically sent via e-mail to the person and likewise
entered into</dd>
</dl>

<p>Major NetLab projects:</p>

<dl>
<dt>NWI</dt>
<dd>Nordic Web Index (funded by Nordinfo, BTJ and BIBsam). Initially
meant to become a Nordic search engine build on public service
principles. A distributed search service using individual harvesters
in all Nordic countries. Each member had its own Z39.50 target.  We
started this before AltaVista, but after Lycos, which at the time did
not support European character sets.</dd>

<dt>NWI II (funded by Nordinfo)</dt>
<dd>A continuation of NWI. Working on Metadata, Z39.50
and archiving the Web</dd>

<dt>Desire (EU project)</dt>
<dd>An infrastructure for European researchers. We wrote the Combine
here, generalizing the NWI harvester.</dd>

<dt>Desire II (EU project)</dt>
<dd>We did further improvements on Combine and the search systems for
better metadata support.</dd>

<dt>SAFARI (funded by The Council for Higher Education,
Högskoleverket)</dt>
<dd>I built this -- not very popular but widely known -- system for
research information.</dd>

<dt>ETB (EU project)</dt>
<dd>Building a metadata exchange system for a network of information
gateways, all of which exchanging records by posting them to a NNTP
network</dd>

<dt>STUDERA.nu (funded by The Council for Higher Education,
Högskoleverket)</dt>
<dd>A database for academic courses. Metadata and full text is
collected using harvesting robot, and made accessible using Z39.50.
The user interface is built using a Z39.50 gateway.</dd>
</dl>

<h2>3.2 Standarisation</h2>

<p class="noindent">I have following the standards development in
information retrieval and metadata area since entering this
business. In particular I have actively participated in the Dublin
Core Metadata Initiative (DCMI) since 1996 as working group member in
several groups, and co-chair for the implementors SIG and co-chair
with Dan Brickley, W3C, for the DCMI architecture WG.
Likewise I'm following the development of the Z39.50 protocol and the
work on RDF/XML and the semantic web.</p>


</body>
</html>
